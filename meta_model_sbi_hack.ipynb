{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pulkit-20-g/PSB-hack-SBI/blob/main/meta_model_sbi_hack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc9FqabE5wM-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWNWBKoh6Gpz"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/HACKATHON_TRAINING_DATA.CSV\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llzowc88GeUn"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTVeDAiQA5QS"
      },
      "source": [
        " INDICATES\n",
        "\n",
        "This is a binary indicator (usually 0 or 1) that tells whether a Standing Instruction (SI) has been set on the account.\n",
        "\n",
        "ðŸ” What is a Standing Instruction?\n",
        "A Standing Instruction is a pre-authorized instruction from a customer to the bank to automatically debit a fixed amount at regular intervals from their accountâ€”commonly used for:\n",
        "\n",
        "Loan EMI payments\n",
        "Credit card payments\n",
        "Recurring bill payments (like rent, utilities)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l59QlVnYHVA-"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujx-rogXHjK5"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnzsTTLGAOZd"
      },
      "source": [
        "easy prediction model you have been given target 0 and 1 iss pe eak neural network ko train karna hai and another walein pe test karna haii use multiple models to evaluate the accuracy which parameteres are most suitable pehle toh ye dekho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWFiwEcfHmQ8"
      },
      "outputs": [],
      "source": [
        "arr=df.columns\n",
        "for i in arr:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qZZhr-rNbbC"
      },
      "outputs": [],
      "source": [
        "for i in arr:\n",
        "     print(i,df[i].dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUEIq4MABkcU"
      },
      "source": [
        "OBJECT: AVERAGE_ACCT_AGE1\n",
        "CREDIT_HISTORY_LENGTH1,INCOME_BAND1 ,AGREG_GROUP,PRODUCT_TYPE TIME_PERIOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtLDq133CaSb"
      },
      "outputs": [],
      "source": [
        "object_cols = [\n",
        "    \"AVERAGE_ACCT_AGE1\",\n",
        "    \"CREDIT_HISTORY_LENGTH1\",\n",
        "    \"INCOME_BAND1\",\n",
        "    \"AGREG_GROUP\",\n",
        "    \"PRODUCT_TYPE\",\n",
        "    \"TIME_PERIOD\"\n",
        "]\n",
        "\n",
        "# Inspect unique values for each\n",
        "for col in object_cols:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(\"Unique values:\", df[col].unique())\n",
        "    print(\"Value counts:\\n\", df[col].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja7lHwZRC2GK"
      },
      "source": [
        "### changing the object type to int or float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG17lJNrC7nQ"
      },
      "source": [
        "### 1.AVERAGE_ACCT_AGE1 and CREDIT_HISTORY_LENGTH1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZcwJaOICx_y"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def convert_to_months(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    match = re.match(r'(\\d+)yrs\\s+(\\d+)mon', x)\n",
        "    return int(match.group(1)) * 12 + int(match.group(2)) if match else np.nan\n",
        "\n",
        "df['AVERAGE_ACCT_AGE1'] = df['AVERAGE_ACCT_AGE1'].apply(convert_to_months)\n",
        "df['CREDIT_HISTORY_LENGTH1'] = df['CREDIT_HISTORY_LENGTH1'].apply(convert_to_months)\n",
        "\n",
        "# Optional: Impute missing with median\n",
        "df['AVERAGE_ACCT_AGE1'].fillna(df['AVERAGE_ACCT_AGE1'].median(), inplace=True)\n",
        "df['CREDIT_HISTORY_LENGTH1'].fillna(df['CREDIT_HISTORY_LENGTH1'].median(), inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksQOjO8C_Sj"
      },
      "source": [
        "### 2. INCOME_BAND1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pykPIVzoC1L6"
      },
      "outputs": [],
      "source": [
        "income_band_map = {\n",
        "    'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8,\n",
        "    'EX01': 9, 'EX02': 10, 'EX04': 11, 'EX05': 12\n",
        "}\n",
        "df['INCOME_BAND1'] = df['INCOME_BAND1'].map(income_band_map)\n",
        "\n",
        "# Optional: Fill NaN with median or 0\n",
        "df['INCOME_BAND1'].fillna(df['INCOME_BAND1'].median(), inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9DbH_KJDIRU"
      },
      "source": [
        "### 3. AGREG_GROUP, PRODUCT_TYPE, TIME_PERIOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVSntm7LDFg0"
      },
      "outputs": [],
      "source": [
        "# One-hot encode\n",
        "df = pd.get_dummies(df, columns=['AGREG_GROUP', 'PRODUCT_TYPE', 'TIME_PERIOD'], drop_first=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10z_SD1LEmD2"
      },
      "source": [
        "Code to Identify Non-Numeric Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gBivQf8DaCv"
      },
      "outputs": [],
      "source": [
        "# Get columns not of int or float dtype\n",
        "non_numeric_cols = df.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(\"Columns that are NOT int or float:\")\n",
        "for col in non_numeric_cols:\n",
        "    print(f\"{col} --> {df[col].dtype}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwnlBTx1FKRQ"
      },
      "source": [
        "Convert Boolean Columns to Integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly9IzCCxFJpD"
      },
      "outputs": [],
      "source": [
        "# Identify boolean columns\n",
        "bool_cols = df.select_dtypes(include='bool').columns\n",
        "\n",
        "# Convert to integer type\n",
        "df[bool_cols] = df[bool_cols].astype(int)\n",
        "\n",
        "print(f\"âœ… Converted {len(bool_cols)} boolean columns to integers.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX1JRv5FHeFe"
      },
      "source": [
        "check remaining columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaWuLKr5HhdN"
      },
      "outputs": [],
      "source": [
        "ck=['SI_FLG','LOCKER_HLDR_IND','UID_FLG','KYC_FLG','INB_FLG','EKYC_FLG']\n",
        "for col in ck:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(\"Unique values:\", df[col].unique())\n",
        "    print(\"Value counts:\\n\", df[col].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAWFPAxzInH-"
      },
      "source": [
        "convert to int for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBsPAtMqImRN"
      },
      "outputs": [],
      "source": [
        "# List of binary flag columns\n",
        "binary_flags = ['SI_FLG', 'LOCKER_HLDR_IND', 'UID_FLG', 'KYC_FLG', 'INB_FLG', 'EKYC_FLG']\n",
        "\n",
        "# Step 1: Drop rows where KYC_FLG is '1' or '2'\n",
        "df = df[~df['KYC_FLG'].isin(['1', '2'])]\n",
        "\n",
        "# Step 2: Convert Y/N to 1/0, leave NaNs as-is\n",
        "for col in binary_flags:\n",
        "    df[col] = df[col].map({'Y': 1, 'N': 0})\n",
        "\n",
        "# Confirm changes\n",
        "print(\"âœ… Binary flags cleaned and KYC_FLG filtered. Remaining values:\")\n",
        "for col in binary_flags:\n",
        "    print(f\"{col} --> Unique values: {df[col].unique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPX4iAsJIue9"
      },
      "outputs": [],
      "source": [
        "# check\n",
        "# Get columns not of int or float dtype\n",
        "non_numeric_cols = df.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(\"Columns that are NOT int or float:\")\n",
        "for col in non_numeric_cols:\n",
        "    print(f\"{col} --> {df[col].dtype}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAlM3SyOIxkS"
      },
      "source": [
        "NOW ALL THE COLUMNS ARE INTEGER TYPE / FLOAT TYPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ffyddJ_JBkD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "missing_counts = df.isnull().sum()\n",
        "# Create a DataFrame for better formatting\n",
        "missing_df = missing_counts.sort_values(ascending=False).reset_index()\n",
        "missing_df.columns = ['Column', 'MissingValues']\n",
        "\n",
        "# Display all rows\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "print(\"ðŸ” Columns with missing values:\")\n",
        "print(missing_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq1wkobaJz-_"
      },
      "source": [
        "## HANDLING THE NNULL VALUES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcW8wTTRJ6Dl"
      },
      "source": [
        "Drop high-null columns (too sparse to be useful)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB75ucspJ2nI"
      },
      "outputs": [],
      "source": [
        "# Drop columns with >150,000 missing values (roughly 45%+ missing)\n",
        "high_null_cols = df.columns[df.isnull().sum() > 150000]\n",
        "df.drop(columns=high_null_cols, inplace=True)\n",
        "print(f\"Dropped high-null columns: {list(high_null_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukyV-fwwJ9ZH"
      },
      "source": [
        "Fill monthly transaction behavior columns with 0 (assumes \"no activity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBCkJPctKA9t"
      },
      "outputs": [],
      "source": [
        "monthly_cols = [col for col in df.columns if any(key in col for key in [\n",
        "    'MNTHSCR', 'MNTHSDR', 'AVGMTD', 'AVGQTD', 'AVGYTD', 'OUTSTANGBAL'])]\n",
        "\n",
        "df[monthly_cols] = df[monthly_cols].fillna(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFJhES-jKIG6"
      },
      "source": [
        "3. Impute credit bureau and CRIFF columns with media (skewed distributions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmR32GvhKEYH"
      },
      "outputs": [],
      "source": [
        "bureau_cols = [col for col in df.columns if any(key in col for key in [\n",
        "    'CRIFF_', 'PRI_', 'PRIMARY_INSTAL_AMT', 'TOTAL_CRIFF1', 'DEC_CRIFFCHNG1', 'NO_OF_INQUIRIES1'])]\n",
        "\n",
        "df[bureau_cols] = df[bureau_cols].fillna(df[bureau_cols].median())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6i1GncGKQlc"
      },
      "source": [
        "4. Impute general numeric columns (e.g., AGE, tenure fields) with median\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvAnXLOGKK5A"
      },
      "outputs": [],
      "source": [
        "general_cols = ['AGE', 'VINTAGE', 'KYC_SCR', 'ACCT_RESIDUAL_TENURE',\n",
        "                'LATEST_RESIDUAL_TENURE', 'OLDEST_RESIDUAL_TENURE',\n",
        "                'LATEST_CR_DAYS', 'LATEST_RG3_TENURE', 'NO_YRS_RG3']\n",
        "\n",
        "df[general_cols] = df[general_cols].fillna(df[general_cols].median())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxNlofL3Ken9"
      },
      "source": [
        "5. Drop rows with remaining minimal nulls in critical flag columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM7fxx3AKdtC"
      },
      "outputs": [],
      "source": [
        "final_check_cols = ['UID_FLG', 'KYC_FLG', 'INB_FLG', 'EKYC_FLG', 'LOCKER_HLDR_IND', 'POP_CODE']\n",
        "\n",
        "# Drop rows if any of these critical flags are still null\n",
        "df.dropna(subset=final_check_cols, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfS9LTW8KwqF"
      },
      "outputs": [],
      "source": [
        "missing_cols = df.columns[df.isnull().any()]\n",
        "print(\"Columns with missing values:\")\n",
        "print(df[missing_cols].isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw9SSqUiLPAj"
      },
      "outputs": [],
      "source": [
        "fill_zero_cols = [\n",
        "    'ONEMNTHCR',\n",
        "    'LAST_1_YR_RG2',\n",
        "    'LAST_1_YR_RG1',\n",
        "    'NEW_ACCTS_IN_LAST_SIX_MONTHS1',\n",
        "    'DELINQUENT_ACCTS_IN_LAST_SIX_MONTHS1'\n",
        "]\n",
        "\n",
        "# Fill all with 0\n",
        "df[fill_zero_cols] = df[fill_zero_cols].fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYawqSfBLQCo"
      },
      "outputs": [],
      "source": [
        "print(\"Remaining null values:\", df.isnull().sum().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYmAcrEFMXId"
      },
      "source": [
        "Outlier Handling Code (Safe for Large Datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMjdGz9pLTtZ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Select only continuous numeric columns (exclude flags, indicators, dummies)\n",
        "excluded_keywords = ['FLG', 'IND', 'CODE', 'TYPE', 'TENURE', 'NO_', 'KYC', 'CRIFF', 'RG', 'POP', 'TIME', 'TARGET']\n",
        "numeric_cols = [col for col in df.columns\n",
        "                if df[col].dtype in ['float64', 'int64']\n",
        "                and not any(key in col.upper() for key in excluded_keywords)]\n",
        "\n",
        "print(f\"âœ… Number of numeric columns selected for outlier clipping: {len(numeric_cols)}\")\n",
        "\n",
        "# Step 2: Clip outliers at the 1st and 99th percentile for each column\n",
        "for col in numeric_cols:\n",
        "    lower = df[col].quantile(0.01)\n",
        "    upper = df[col].quantile(0.99)\n",
        "    df[col] = df[col].clip(lower, upper)\n",
        "\n",
        "print(\"âœ… Outlier clipping complete using 1stâ€“99th percentile.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYO2vfaVMj2C"
      },
      "source": [
        "### NOW LETS START MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B05lRgSqMnyw"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['TARGET'])  # Features\n",
        "y = df['TARGET']                 # Target (0 = non-defaulter, 1 = defaulter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a0bApJDMq46"
      },
      "outputs": [],
      "source": [
        "df_pred=pd.read_csv('/content/HACKATHON_PREDICTION_DATA.CSV')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxTxVm7nOB5R"
      },
      "outputs": [],
      "source": [
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXcsXZMXOXR6"
      },
      "source": [
        "ANALYSE df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8zyt-m1OStw"
      },
      "outputs": [],
      "source": [
        "print(\"Shape:\", df_pred.shape)\n",
        "print(\"Columns:\", df_pred.columns.tolist()[:10], \"...\")\n",
        "\n",
        "# Check if 'TARGET' is present (it shouldn't be)\n",
        "if 'TARGET' in df_pred.columns:\n",
        "    print(\"TARGET column found in prediction data â€” please verify!\")\n",
        "else:\n",
        "    print(\"No TARGET column in prediction data â€” looks good.\")\n",
        "\n",
        "# Compare column names with training set (assuming df already cleaned)\n",
        "common_cols = [col for col in df.columns if col in df_pred.columns]\n",
        "missing_in_pred = [col for col in df.columns if col not in df_pred.columns]\n",
        "\n",
        "print(f\"\\nCommon columns with training set: {len(common_cols)}\")\n",
        "print(f\"Missing columns in prediction set: {missing_in_pred}\")\n",
        "\n",
        "# Check for nulls\n",
        "null_summary = df_pred.isnull().sum()\n",
        "null_summary = null_summary[null_summary > 0].sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nðŸ” Columns with missing values in df_pred:\")\n",
        "print(null_summary.to_string())\n",
        "\n",
        "# Summary stats of numeric features\n",
        "print(\"\\nðŸ“Š Summary statistics of numeric columns:\")\n",
        "print(df_pred.describe().T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EkDgVg9PcPj"
      },
      "outputs": [],
      "source": [
        "print(\"Shape:\", df_pred.shape)\n",
        "print(\"Columns:\", df_pred.columns.tolist()[:10], \"...\")\n",
        "\n",
        "common_cols = [col for col in df.columns if col in df_pred.columns]\n",
        "missing_in_pred = [col for col in df.columns if col not in df_pred.columns]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aevLgYIQPiIK"
      },
      "outputs": [],
      "source": [
        "df_pred.describe().T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tolqrf8sQEjp"
      },
      "source": [
        "### ANALYSED THE PREDICTION DATA SET NEED TO DO CLEANING AND ALL OF THIS ALSO BUT FIRST LETS BUILD UP ON THE MODEL AND THEN WILL DO THIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eACV9yr4QQ-4"
      },
      "source": [
        "LETS CHECK IF THE DATA SET IS IMBALANCED OR NOT??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awP2wUrvQMou"
      },
      "outputs": [],
      "source": [
        "# Check target distribution\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "target_counts = df['TARGET'].value_counts(normalize=True) * 100\n",
        "print(\"ðŸ”¢ Class Distribution (%):\")\n",
        "print(target_counts)\n",
        "\n",
        "# Optional: Bar plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(data=df, x='TARGET')\n",
        "plt.title('Target Variable Distribution')\n",
        "plt.xlabel('Defaulter (1 = Yes, 0 = No)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2DTP_TWSXDR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0-img53SX1W"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['TARGET'])\n",
        "y = df['TARGET']\n",
        "\n",
        "# STEP 2: Train-Test Split (Stratified for imbalance)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7YgQdUcSfA5"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Eb9TCVPSgHm"
      },
      "outputs": [],
      "source": [
        "# STEP 4: Compute Class Weights\n",
        "class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights_array))\n",
        "print(\"âœ… Class Weights:\", class_weight_dict)\n",
        "\n",
        "# STEP 5: Build the Neural Network Model\n",
        "def build_nn_model():\n",
        "    model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# STEP 4: Compute Class Weights\n",
        "class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights_array))\n",
        "print(\"âœ… Class Weights:\", class_weight_dict)\n",
        "\n",
        "# STEP 5: Build the Neural Network Model\n",
        "def build_nn_model():\n",
        "    model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# STEP 6: Compile the Model\n",
        "    model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "    return model\n",
        "\n",
        "# STEP 7: Train the Model with Validation\n",
        "nn = build_nn_model()\n",
        "history = nn.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=512,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# STEP 8: Save the Model\n",
        "nn.save(\"defaulter_model.h5\")\n",
        "print(\"ðŸ“¦ Model saved as defaulter_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW7dOdXgq-Nb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Assuming X and y are already defined and preprocessed from the previous steps\n",
        "# X = df.drop(columns=['TARGET'])  # Features\n",
        "# y = df['TARGET']                 # Target\n",
        "\n",
        "# --- Cross-Validation Setup ---\n",
        "n_splits = 5  # Define the number of folds for cross-validation\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# --- Store Results ---\n",
        "fold_results = []\n",
        "all_confusion_matrices = []\n",
        "all_classification_reports = []\n",
        "\n",
        "# --- K-Fold Cross-Validation Loop ---\n",
        "fold_no = 1\n",
        "for train_index, val_index in kf.split(X):\n",
        "    print(f\"--- Processing Fold {fold_no}/{n_splits} ---\")\n",
        "\n",
        "    # Split data into training and validation sets for the current fold\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Scale the data for the current fold\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "    # Compute Class Weights for the current fold's training data (optional but recommended for imbalance)\n",
        "    class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weight_dict = dict(enumerate(class_weights_array))\n",
        "    print(\"âœ… Class Weights for this fold:\", class_weight_dict)\n",
        "\n",
        "    # Build the Neural Network Model\n",
        "    # Model architecture is defined inside the loop to ensure a fresh start for each fold\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the Model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    # Train the Model\n",
        "    history = model.fit(\n",
        "        X_train_scaled, y_train,\n",
        "        epochs=50, # You might adjust epochs based on monitoring validation performance\n",
        "        batch_size=512,\n",
        "        validation_data=(X_val_scaled, y_val),\n",
        "        class_weight=class_weight_dict,\n",
        "        verbose=0 # Set to 1 or 2 for more detailed output during training\n",
        "    )\n",
        "\n",
        "    # Evaluate the Model on the validation set for the current fold\n",
        "    loss, accuracy, auc = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
        "    print(f\"Fold {fold_no} Evaluation: Loss={loss:.4f}, Accuracy={accuracy:.4f}, AUC={auc:.4f}\")\n",
        "\n",
        "    # Store results for this fold\n",
        "    fold_results.append({'fold': fold_no, 'loss': loss, 'accuracy': accuracy, 'auc': auc})\n",
        "\n",
        "    # Generate and store confusion matrix and classification report for this fold\n",
        "    y_val_pred_prob = model.predict(X_val_scaled, verbose=0)\n",
        "    y_val_pred = (y_val_pred_prob > 0.5).astype(int) # Using 0.5 as threshold\n",
        "\n",
        "    cm = confusion_matrix(y_val, y_val_pred)\n",
        "    all_confusion_matrices.append({'fold': fold_no, 'confusion_matrix': cm})\n",
        "\n",
        "    report = classification_report(y_val, y_val_pred, target_names=['Non-Defaulter', 'Defaulter'], output_dict=True)\n",
        "    all_classification_reports.append({'fold': fold_no, 'report': report})\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# --- Summarize Results ---\n",
        "print(\"\\n--- Cross-Validation Summary ---\")\n",
        "results_df = pd.DataFrame(fold_results)\n",
        "print(results_df)\n",
        "\n",
        "print(\"\\nMean Performance Across Folds:\")\n",
        "print(results_df[['accuracy', 'auc', 'loss']].mean())\n",
        "\n",
        "# You can further analyze the stored confusion matrices and classification reports\n",
        "# For example, to see the report for the first fold:\n",
        "# print(\"\\nClassification Report for Fold 1:\")\n",
        "# print(all_classification_reports[0]['report'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tki2DWch0zDJ"
      },
      "outputs": [],
      "source": [
        "!pip install scikeras[tensorflow]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRkO0qiCuT5V"
      },
      "outputs": [],
      "source": [
        "# 9. Train LightGBM model\n",
        "import lightgbm as lgb\n",
        "lgbm = lgb.LGBMClassifier(n_estimators=200, class_weight='balanced', random_state=42)\n",
        "lgbm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 10. Wrap NN for stacking\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "nn_wrapper = KerasClassifier(build_fn=build_nn_model,\n",
        "                             epochs=50,\n",
        "                             batch_size=512,\n",
        "                             class_weight=class_weight_dict,\n",
        "                             verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z7WXCBcA_ol4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_curve,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# 1) Prepare storage for out-of-fold predictions\n",
        "n_train = X_train_scaled.shape[0]\n",
        "oof_probs = np.zeros((n_train, 2))  # col0: NN, col1: LGBM\n",
        "\n",
        "kf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_scaled, y_train)):\n",
        "    # a) Train fresh copies on the train-fold\n",
        "    nn_fold = build_nn_model()\n",
        "    nn_fold.fit(\n",
        "        X_train_scaled[train_idx],\n",
        "        y_train.iloc[train_idx],         # â† use original y_train here\n",
        "        epochs=50,\n",
        "        batch_size=512,\n",
        "        class_weight=class_weight_dict,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    lgbm_fold = lgb.LGBMClassifier(\n",
        "        n_estimators=200,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    )\n",
        "    lgbm_fold.fit(\n",
        "        X_train_scaled[train_idx],\n",
        "        y_train.iloc[train_idx]          # â† and here\n",
        "    )\n",
        "\n",
        "    # b) Predict on the foldâ€™s validation slice\n",
        "    oof_probs[val_idx, 0] = nn_fold.predict(X_train_scaled[val_idx]).ravel()\n",
        "    oof_probs[val_idx, 1] = lgbm_fold.predict_proba(X_train_scaled[val_idx])[:, 1]\n",
        "\n",
        "# 2) Train meta-learner on those OOF predictions\n",
        "meta = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "meta.fit(oof_probs, y_train.values)\n",
        "\n",
        "# 3) Build meta-features for your held-out validation set\n",
        "val_probs_nn   = nn.predict(X_val_scaled).ravel()\n",
        "val_probs_lgbm = lgbm.predict_proba(X_val_scaled)[:, 1]\n",
        "meta_features  = np.vstack([val_probs_nn, val_probs_lgbm]).T\n",
        "\n",
        "# 4) Meta-modelâ€™s final probabilities\n",
        "final_probs = meta.predict_proba(meta_features)[:, 1]\n",
        "\n",
        "# 5) Threshold tuning\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, final_probs)\n",
        "target_recall = 0.85\n",
        "ix = np.argmin(np.abs(recall - target_recall))\n",
        "opt_thresh = thresholds[ix]\n",
        "\n",
        "# 6) Evaluate at that threshold\n",
        "y_pred = (final_probs >= opt_thresh).astype(int)\n",
        "print(f\"Blended Precision: {precision_score(y_val, y_pred):.3f}\")\n",
        "print(f\"Blended Recall   : {recall_score   (y_val, y_pred):.3f}\")\n",
        "print(f\"Blended ROC AUC  : {roc_auc_score(y_val, final_probs):.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umQs-Hm9_x4e"
      },
      "outputs": [],
      "source": [
        "# 7) Save the blended pipeline\n",
        "import joblib\n",
        "joblib.dump({\n",
        "    'nn_model'  : nn,\n",
        "    'lgbm_model': lgbm,\n",
        "    'meta_model': meta,\n",
        "    'scaler'    : scaler,\n",
        "    'threshold' : opt_thresh\n",
        "}, 'defaulter_blend.pkl')\n",
        "print(\"âœ… Blended pipeline saved to defaulter_blend.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# assuming youâ€™ve already got:\n",
        "#   final_probs = meta.predict_proba(meta_features)[:,1]\n",
        "#   opt_thresh  = your chosen threshold (e.g. for 85% recall)\n",
        "#   y_pred      = (final_probs >= opt_thresh).astype(int)\n",
        "\n",
        "print(classification_report(\n",
        "    y_val,\n",
        "    y_pred,\n",
        "    target_names=['Non-Defaulter','Defaulter']\n",
        "))\n"
      ],
      "metadata": {
        "id": "2Ge4DcR-JmoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "USE PRECISION RECALL TRADEOFF (OPTIONAL)\n"
      ],
      "metadata": {
        "id": "vKeSTrJpLvFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EWI4tO2L3wEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONFUSION MATRIX**"
      ],
      "metadata": {
        "id": "89WQnABJL3th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Assuming you already have:\n",
        "#    final_probs = meta.predict_proba(meta_features)[:, 1]\n",
        "#    opt_thresh  = your chosen threshold (e.g. ~0.37)\n",
        "#    y_pred      = (final_probs >= opt_thresh).astype(int)\n",
        "\n",
        "# 2. Compute the confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "print(f\"True Negatives : {tn}\")\n",
        "print(f\"False Positives: {fp}\")\n",
        "print(f\"False Negatives: {fn}\")\n",
        "print(f\"True Positives : {tp}\")\n",
        "\n",
        "# 3. (Optional) Plot it with Matplotlib\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, cmap='Blues', interpolation='nearest')\n",
        "ax.set_xticks([0,1])\n",
        "ax.set_yticks([0,1])\n",
        "ax.set_xticklabels(['Non-Defaulter', 'Defaulter'])\n",
        "ax.set_yticklabels(['Non-Defaulter', 'Defaulter'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# annotate each cell\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center')\n",
        "\n",
        "plt.colorbar(im, ax=ax)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JCIiueACLSkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "16T_3yyrUWWa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52Gih8GsUwHO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}